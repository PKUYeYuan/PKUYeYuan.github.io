机器学习通俗来讲指的是计算机程序通过经验来提高某任务处理性能的一类技术。其形式化定义如下：

> 对于某类任务T和性能度量P，如果一个计算机程序在T上以P衡量的性能随着经验E而自我完善，那么我们称这个计算机程序在从经验E中进行**学习**。

一个机器学习方法需要包括三个要素，也称为机器学习三要素：模型、学习准则、优化算法。

### 模型

机器学习的本质是根据经验学习一个映射函数$f: X \rightarrow Y$，用于对未知数据进行预测。模型结构确定了该机器学习算法的**假设空间**，即所有可能的映射函数的集合。例如，如果映射函数$f$具有如下的形式：$f_\theta = \theta_1x + \theta_0$，那么该假设空间实际上是平面上的所有直线；如果映射函数$f$具有如下的形式：$f = W_2(\sigma(W_1X+b_1))+b_2$，那么该假设空间是所有以$\sigma$函数作为激活函数的两层线性神经网络构成的集合。

我们在设计模型时应该尽量使得得到的假设空间包含或者尽可能近似目标映射，同时排出其余不是最优解的候选映射。

### 学习准则

在设计完模型（通常对于机器学习是选定模型）得到假设空间以后，我们接下来需要做的是找到一种评价指标能够对假设空间中的映射进行比较，也就是通常所说的学习准则。

通常我们会根据不同的任务需求选定一个损失函数用以对模型相对于数据点的预测结果进行评估。比如：最小二乘损失，绝对值损失，交叉熵损失，Hinge Loss，Huber Loss等。

在得到损失函数以后，我们通常还会挑选一种策略来得到最终的优化目标。比如，经验风险最小化、结构风险最小化、贝叶斯准则等等。

#### 经验风险最小化

假设对于一个数据点的预测结果得到的损失记为$loss(f(x),y)$，那么该损失函数相对于整个数据集的期望就是风险函数或者叫做期望损失。
$$
Expected\_Loss = E_{(x,y) \sim P_D} [loss(f(x), y)]
$$
但是由于我们不知道数据集的真实分布$P_D$，因此只能对期望损失进行估计。一般我们使用损失函数在当前数据集的平均值作为对期望损失的估计，这个值又叫做经验风险或者叫做经验损失。
$$
Empirical\_Loss = \frac{1}{N} \sum_{i=1}^N loss(f(x_i), y_i)
$$
把经验风险作为目标函数对其进行最小化的准则就叫做经验风险最小化准则。

#### 结构风险最小化

结构风险最小化准则是在经验风险最小化的基础上添加了正则项用以防止过拟合。

结构风险 = 经验风险 + L2正则项

L2正则项主要是限制了模型的复杂度，从而防止过拟合。从优化的角度L2正则可以看作是一个拉格朗日算子，从贝叶斯学习的角度来看，L2正则是对参数加入了高斯先验。

### 优化算法

优化算法是将学习准则得到的目标函数作为优化目标，从假设空间找到一个使得目标函数最大化/最小化的算法。

目前深度学习的优化算法都是基于梯度反向传播的优化算法。

对于机器学习来说，不同的方法具有不同的优化算法。例如SMO是SVM的优化算法，尺度迭代算法是最大熵模型的优化算法，EM算法通常用于包含隐变量的模型的优化。